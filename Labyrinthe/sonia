Architecture typique :
	â€¢	ChaÃ®ne de traitement en 4 Ã©tapes :
	1.	PrÃ©-traitement audio : dÃ©tection de bruit, sÃ©paration des canaux, normalisation.
	2.	Reconnaissance vocale (ASR) : transcription automatique, multilingue, parfois avec sÃ©paration des locuteurs (diarisation).
	3.	Traduction automatique (NMT) : si enregistrement dans une autre langue.
	4.	RÃ©sumÃ© et analyse IA (LLM) : synthÃ¨se de contenu, extraction dâ€™Ã©lÃ©ments clÃ©s (actions, dÃ©cisions, mots-clÃ©s, sentimentsâ€¦).

question :
	1.	Quel moteur ASR utilisez-vous ? PropriÃ©taire ou Whisper, DeepSpeech, etc. ?
	2.	Est-il possible dâ€™avoir un traitement on-premise pour des besoins sensibles ?
	3.	Quel est le delai moyen de traitement pour une heure dâ€™audio ?
	4.	Les modÃ¨les peuvent-ils Ãªtre adaptÃ©s Ã  un vocabulaire mÃ©tier (jargon, acronymes) ?
	5.	Lâ€™audio est-il stockÃ© temporairement ou dÃ©finitivement ? Peut-on automatiser lâ€™effacement ?
  6. Diarisation ? identifier locuteur ?

Audio & Traitement vocal
	â€¢	ASR (Automatic Speech Recognition) : Reconnaissance vocale automatique. Câ€™est la technologie qui convertit la voix en texte. Exemple : Whisper dâ€™OpenAI.
	â€¢	Diarisation : Technique permettant dâ€™identifier et de distinguer les diffÃ©rents locuteurs dans un enregistrement audio (ex : Â« Speaker 1 Â», Â« Speaker 2 Â»â€¦).
	â€¢	Segmentation audio : DÃ©coupage automatique dâ€™un enregistrement en morceaux pertinents (par locuteur, par thÃ¨me, par phraseâ€¦).
	â€¢	Transcription : Conversion dâ€™un enregistrement audio en texte.
	â€¢	Speech-to-Text : Synonyme courant dâ€™ASR (voir plus haut).
	â€¢	Audio prÃ©-processing : Traitement prÃ©alable (rÃ©duction du bruit, normalisation du volume, dÃ©tection de silenceâ€¦).

â¸»

ğŸŒ Traduction & NLP
	â€¢	NMT (Neural Machine Translation) : Traduction automatique basÃ©e sur des rÃ©seaux de neurones. Exemples : DeepL, Google Translate, etc.
	â€¢	LLM (Large Language Model) : ModÃ¨le de langage de grande taille. Il peut faire du rÃ©sumÃ©, de la gÃ©nÃ©ration de texte, de la comprÃ©hension de langage, etc. Exemple : GPT-4, Falcon, Mistralâ€¦
	â€¢	RÃ©sumÃ©s extractifs / abstratifs :
	â€¢	Extractif : extrait des phrases directement du texte source.
	â€¢	Abstratif : reformule avec ses propres mots (ex : un LLM).
	â€¢	NER (Named Entity Recognition) : Reconnaissance des entitÃ©s nommÃ©es (personnes, lieux, datesâ€¦) dans un texte.

IA & performance
	â€¢	Inference time : Temps que prend un modÃ¨le pour produire un rÃ©sultat Ã  partir dâ€™une entrÃ©e (ex : transcrire un fichier audio).
	â€¢	Fine-tuning : Personnalisation dâ€™un modÃ¨le dâ€™IA en lâ€™entraÃ®nant sur des donnÃ©es spÃ©cifiques (ex : jargon mÃ©tier, noms propres).

Traitement du langage

NLP (Natural Language Processing)

Traitement automatique du langage naturel.
UtilisÃ© pour comprendre, rÃ©sumer, classer ou extraire du sens depuis un texte ou une transcription.
ğŸ”¹ Exemple dans SonIA : repÃ©rage des intentions, des entitÃ©s (personnes, lieux), des rÃ©sumÃ©s intelligents.

â¸»

ğŸ›ï¸ Traitement audio

EQ (Equalizer / Ã‰galiseur audio)

Ajustement des frÃ©quences audio (graves, mÃ©diums, aigus) pour amÃ©liorer la clartÃ© ou retirer certains bruits.
UtilisÃ© au stade du prÃ©-traitement audio, souvent automatiquement, pour â€œnettoyerâ€ lâ€™enregistrement.

ğŸ”¹ Exemple : rÃ©duction dâ€™un souffle constant ou accentuation de la voix humaine autour de 1â€“4 kHz.

â¸»

OTT (Over-The-Top)

Terme issu de lâ€™audiovisuel, dÃ©signe les services diffusÃ©s via Internet sans infrastructure opÃ©rateur (comme Netflix ou Zoom).

Dans un contexte SonIA / ChapsVision, cela peut dÃ©signer :
	â€¢	Des communications OTT interceptÃ©es (WhatsApp, Signal, Telegram, etc.),
	â€¢	Des flux audio provenant de services distants (visio, cloud),
	â€¢	Ou des outils intÃ©grÃ©s Ã  des plateformes OTT.
